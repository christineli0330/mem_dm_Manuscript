---
title: "Visualization for mem-dm Manuscript"
author: "Xinyue Li"
date: "10/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(lme4)
library(readr)
library(tidyr)
library(ggplot2)
library(sjPlot)
library(sjmisc)
library(Hmisc)
#library(plyr)
library(RColorBrewer)
library(reshape2)
library(glmmTMB)
library(corrplot)
require(gridExtra)

setwd("C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization")
mem = read.csv("C:/Users/Christine/Box Sync/data/mem_dm_all_results/cleaned data/cleaned_all_mem.csv")
food = read.csv("C:/Users/Christine/Box Sync/data/mem_dm_all_results/raw data/stimchar_final_touse.csv") %>% filter(age == "18-25" | age == "26-30" | age == "31-35") 
choice = read.csv('C:/Users/Christine/Box Sync/data/mem_dm_all_results/cleaned data/image/cleaned_choice.csv')
rating = read.csv('C:/Users/Christine/Box Sync/data/mem_dm_all_results/cleaned data/image/cleaned_rating.csv')
rep = read.csv('C:/Users/Christine/Box Sync/data//mem_dm_all_results/cleaned data/rep-mean.csv') %>% select(-X, -n)
mem = merge(rep, mem, by.x = "word", by.y = "food.item.e")

## z-score values for each subject
#calculate z scores within each ID
rating.merge = rating[c('ID', 'z', 'image')]
rating.merge.l = rating.merge %>% dplyr::rename(stim_left = image)
rating.merge.r = rating.merge %>% dplyr::rename(stim_right = image)

#merge columns based on ID and stimuli names
choice.z = merge(rating.merge.l, choice, by = c('ID', 'stim_left')) %>%
  dplyr::rename(z.value.l = z)
choice.z = merge(rating.merge.r, choice.z, by = c('ID', 'stim_right')) %>% 
  dplyr::rename(z.value.r = z)
choice.z = choice.z %>% mutate(z.delta.value = z.value.r - z.value.l)
#calculate abs z delta value
choice.z = choice.z %>% mutate(abs.delta.v.z = abs(z.delta.value),
                               chosehigh.value = case_when(choseright == 1 & delta.value >=0 ~ 1, choseright == 0 & delta.value <0 ~ 1, choseright == 1 & delta.value <0 ~ 0,choseright == 0 & delta.value >=0 ~ 0 ))

```

## Experiment 1A

Will add images for extreme foods

```{r scatter}
## ggplot histogram
ggplot(mem, aes(x=Memorability)) + 
  geom_histogram(color="steelblue", fill="white", bins = 25) + 
  geom_vline(xintercept = 0.48,linetype = "dashed") +
  theme_classic()

ggsave('hist.png', width = 7, height = 4, units = 'in')
```



### Scatter plot (maybe Supplement)

Figure 3. Scatter plot for memorability scores and averaged tastiness score for the factor analysis on each food item.  
Will add images for the extreme food items

```{r sactter, warning=FALSE}
# factor analysis
rdat = food %>% dplyr::select(stimulus, choice.rating, starts_with("rating"))
colnames(rdat) = sub("rating[.]", "", colnames(rdat))
colnames(rdat) = sub("[.]rating", "", colnames(rdat))

rmat = as.matrix(rdat[,-1])
rownames(rmat) = rdat$stimulus
rmat.nochoice = rmat[,-1]

nFactors::nCng(as.data.frame(rmat.nochoice), model="factors") 
fit <- factanal(rmat.nochoice, 3, scores="regression")

scores3 <- fit$scores
ind1 <- which.max(fit$loadings[rownames(fit$loadings) == "unhealthy",])
ind2 <- which.max(fit$loadings[rownames(fit$loadings) == "tasty",])
ind3 <- which.max(fit$loadings[rownames(fit$loadings) == "sweetsaltysavory",])
colnames(scores3) <- c("Food.UnHealth", "Food.Taste", "Food.SweetProtein")
outdf <- data.frame(subjectId=food$subjectId, stimulus=food$stimulus, scores3)

# score of factor for each food item
ave.factor = outdf %>% group_by(stimulus) %>% 
  summarise_all(mean) 

# add mem score to the factor data frame
labels = sapply(mem$stimulus, function(x) which(ave.factor$stimulus == x))
ave.factor.mem = data.frame(Memorability = mem$Memorability, mem.stimulus = mem$X, ave.factor)

# perform linear regression
fit1 = lm(Memorability ~ Food.Taste + Food.UnHealth + Food.SweetProtein, data = ave.factor.mem)
summary(fit1)

# plot mem~food.taste
ave.factor.mem %>% ggplot(aes(x = Food.Taste, y = Memorability))+
  geom_point(size = 3, alpha = 0.5, color = "steelblue3", fill = "steelblue")+
  geom_smooth(method='lm', color = 'black')+
  xlab('Tastiness')+
  theme_classic()+
  geom_label(
    label="R^2 = 0.07\np = 0.004  ", 
    x=-1.25,
    y=0.1,
    label.padding = unit(0.55, "lines"), # Rectangle size around label
    label.size = 0.35,
    color = "black",
    fill="white"
  )

ggsave('scatter.png', width = 5, height = 4, units = 'in')

```

## Experiment 1B  

### choice ~ image value

```{r}
#generate the model
m.i.v = glmer(chosehigh.value~1+abs.delta.v.z+(1+abs.delta.v.z|ID), 
           data = choice.z, family = "binomial")
plt.value.c = plot_model(m.i.v, type = "pred", terms="abs.delta.v.z [all]")
```


```{r}
library(ggeffects)
p1 <- ggpredict(m.i.v, terms = "abs.delta.v.z [all]") 

p <- ggplot(p1, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p1$conf.low, ymax = p1$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() #+ ylim(0.4, 1.0) + xlim(0,3) 

#calculate mean/sd for each actual data point
choice.v.plt <- choice.z %>% 
  filter(delta.value != 0) %>%
  #dplyr::group_by(ID) %>%
  mutate(bin.value=ntile(abs.delta.v.z, 5))
#for abs.delta.value
choice.plt.ppl = choice.v.plt %>% group_by(bin.value, ID) %>%
  summarise_at(vars(abs.delta.v.z, chosehigh.value), list(mean = mean))
choice.plt.df = choice.plt.ppl %>% group_by(bin.value) %>%
  summarise_at(vars(abs.delta.v.z_mean, chosehigh.value_mean), list(mean = mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.df$lowSE <- choice.plt.df$chosehigh.value_mean_mean - (choice.plt.df$chosehigh.value_mean_sd)/sqrt(44)
choice.plt.df$highSE <- choice.plt.df$chosehigh.value_mean_mean + (choice.plt.df$chosehigh.value_mean_sd)/sqrt(44)

p = p + geom_pointrange(data = choice.plt.df, aes(x = abs.delta.v.z_mean_mean, y = chosehigh.value_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE)+ xlab("Absolute Delta Value") + ylab("Probability of Choosing Higher Valued Item") +
  xlim(0, 3)

p
```

### RT ~ Value  

```{r}
choice.v.plt <- choice.z %>% 
  filter(delta.value != 0) %>%
  dplyr::group_by(ID) %>%
  mutate(bin.value=ntile(abs.delta.v.z, 5))

m3.value = lmer(rt ~ abs.delta.v.z + (abs.delta.v.z|ID), 
           data = choice.v.plt)

p3 <- ggpredict(m3.value, terms = "abs.delta.v.z") 

p.rt.v <- ggplot(p3, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p3$conf.low, ymax = p3$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() + xlim(0,3) 

#calculate mean/sd for each actual data point

#for abs.delta.value
choice.plt.ppl = choice.v.plt %>% group_by(bin.value, ID) %>%
  summarise_at(vars(abs.delta.v.z, chosehigh.value, rt), list(mean = mean))
choice.plt.df = choice.plt.ppl %>% group_by(bin.value) %>%
  summarise_at(vars(abs.delta.v.z_mean, chosehigh.value_mean, rt_mean), list(mean=mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.df$lowSE <- choice.plt.df$rt_mean_mean - (choice.plt.df$rt_mean_sd)/sqrt(44)
choice.plt.df$highSE <- choice.plt.df$rt_mean_mean + (choice.plt.df$rt_mean_sd)/sqrt(44)

p.rt.v.data = p.rt.v + geom_pointrange(data = choice.plt.df, aes(x = abs.delta.v.z_mean_mean, y = rt_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Absolute Delta Value") + ylab("RT") +
  xlim(-0.1,3)

p.rt.v.data
```


### Choice ~ mem (with half sample)  

Run model with data that delta value ~= 0  

BUT delta mem become significant when it is the only predictor in the model

```{r}
## filter data into trials that delta value close to 0
#split trials into high/low delta mem based on within-subject median
choice = choice %>% 
  arrange(ID, abs.mem) %>% 
  group_by(ID) %>% 
  dplyr::mutate(rank = 1:n()) %>% 
  ungroup()
choice.low = choice.z %>% dplyr::group_by(ID) %>% slice(seq(0.5 * n())) %>% 
  mutate(bin.absmem = 1)

# generate the model
m.i.m = glmer(choseright~1+delta.mem+(1+delta.mem|ID),
           data = choice.low, family = "binomial",
           glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
summary(m.i.m)

p2 <- ggpredict(m.i.m, terms = "delta.mem [all]") 

p.mem.choice <- ggplot(p2, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p2$conf.low, ymax = p2$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() 
#+ ylim(0.4, 1.2) + xlim(-0.1,3) 

p.mem.choice = p.mem.choice + scale_y_continuous(labels = scales::percent, limits = c(0,1)) +
  xlab("Delta Memorability") +
  scale_y_continuous(labels = scales::percent, limits = c(0,1))+
  scale_x_continuous(limits = c(-0.8,0.8))

#calculate mean/sd for each actual data point
choice.m.plt <- choice.low %>% 
  dplyr::group_by(ID) %>%
  mutate(bin.mem=ntile(delta.mem, 5))
#for abs.delta.value
choice.plt.mem.ppl = choice.m.plt %>% group_by(bin.mem, ID) %>%
  summarise_at(vars(delta.mem, choseright, rt), list(mean = mean))
choice.plt.mem.df = choice.plt.mem.ppl %>% group_by(bin.mem) %>%
  summarize_at(vars(delta.mem_mean, choseright_mean, rt_mean), list(mean=mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$choseright_mean_mean - (choice.plt.mem.df$choseright_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$choseright_mean_mean + (choice.plt.mem.df$choseright_mean_sd)/sqrt(44)

p.mem.choice = p.mem.choice + geom_pointrange(data = choice.plt.mem.df, aes(x = delta.mem_mean_mean, y = choseright_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("Probability of Choosing Right")

p.mem.choice
```

## for RT vs. mem

```{r}

choice.m.plt = choice.m.plt %>% mutate(abs.delta.m = abs(z.delta.mem))

m4.value = lmer(rt ~ delta.mem + (delta.mem|ID), 
           data = choice.m.plt)

p4 <- ggpredict(m4.value, terms = "delta.mem") 

p.mem.rt <- ggplot(p4, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p4$conf.low, ymax = p4$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic()+ xlim(-0.8,0.8) 


p.mem.rt

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$rt_mean_mean - (choice.plt.mem.df$rt_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$rt_mean_mean + (choice.plt.mem.df$rt_mean_sd)/sqrt(44)

p.mem.rt = p.mem.rt + geom_pointrange(data = choice.plt.mem.df, aes(x = delta.mem_mean_mean, y = rt_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("RT")

p.mem.rt

```


## For absolute delta mem

### choice ~ abs.delta.mem

```{r}
## filter data into trials that delta value close to 0
#split trials into high/low delta mem based on within-subject median
choice = choice %>% 
  arrange(ID, abs.mem) %>% 
  group_by(ID) %>% 
  dplyr::mutate(rank = 1:n()) %>% 
  ungroup()
choice.low = choice.z %>% dplyr::group_by(ID) %>% slice(seq(0.5 * n())) %>% 
  mutate(bin.absmem = 1)

# generate the model
m.i.m = glmer(chosehigh.mem~1+abs.mem+(1+abs.mem|ID),
           data = choice.low, family = "binomial",
           glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
summary(m.i.m)

p2 <- ggpredict(m.i.m, terms = "abs.mem [all]") 

p.mem.choice <- ggplot(p2, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p2$conf.low, ymax = p2$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() 
#+ ylim(0.4, 1.2) + xlim(-0.1,3) 

p.mem.choice = p.mem.choice + scale_y_continuous(labels = scales::percent, limits = c(0,1)) +
  xlab("Delta Memorability") +
  scale_y_continuous(labels = scales::percent, limits = c(0,1))+
  scale_x_continuous(limits = c(0,0.4))

#calculate mean/sd for each actual data point
choice.m.plt <- choice.low %>% 
  dplyr::group_by(ID) %>%
  mutate(bin.mem=ntile(abs.mem, 5))
#for abs.delta.value
choice.plt.mem.ppl = choice.m.plt %>% group_by(bin.mem, ID) %>%
  summarise_at(vars(abs.mem, chosehigh.mem, rt), list(mean = mean))
choice.plt.mem.df = choice.plt.mem.ppl %>% group_by(bin.mem) %>%
  summarize_at(vars(abs.mem_mean, chosehigh.mem_mean, rt_mean), list(mean=mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$chosehigh.mem_mean_mean - (choice.plt.mem.df$chosehigh.mem_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$chosehigh.mem_mean_mean + (choice.plt.mem.df$chosehigh.mem_mean_sd)/sqrt(44)

p.mem.choice = p.mem.choice + geom_pointrange(data = choice.plt.mem.df, aes(x = abs.mem_mean_mean, y = chosehigh.mem_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("Probability of Choosing Right")

p.mem.choice
```

## for RT vs. mem

```{r}

#choice.m.plt = choice.m.plt %>% mutate(abs.delta.m = abs(z.delta.mem))

m4.value = lmer(rt ~ abs.mem + (abs.mem|ID), 
           data = choice.m.plt)

p4 <- ggpredict(m4.value, terms = "abs.mem") 

p.mem.rt <- ggplot(p4, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p4$conf.low, ymax = p4$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic()+ xlim(-0.8,0.8) 


p.mem.rt

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$rt_mean_mean - (choice.plt.mem.df$rt_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$rt_mean_mean + (choice.plt.mem.df$rt_mean_sd)/sqrt(44)

p.mem.rt = p.mem.rt + geom_pointrange(data = choice.plt.mem.df, aes(x = abs.mem_mean_mean, y = rt_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("RT") #+ xlim(-0.2,0.3)

p.mem.rt

```


```{r}
p.image.v = grid.arrange(p, p.rt.v.data, nrow=2)
p.image.m = grid.arrange(p.mem.choice, p.mem.rt, nrow=2)
p.image = grid.arrange(p.image.v, p.image.m, ncol = 2)
ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/im_choice.png', plot = p.image, width = 7, height = 6, units = 'in')
```

## Experiment 2A

### rep data

```{r}
z = median(mem$rep.z)
mem = mem %>% mutate(rep.split = case_when(rep.z <= z ~ "low",
                                           rep.z > z ~ "high"))
rep.low = mem %>% filter(rep.z <=z)
rep.high = mem %>% filter(rep.z > z)

p.rep.low = rep.low %>% ggplot(aes(x = word.mem, y = Memorability))+
  geom_point(size = 3, alpha = 0.5, color = "steelblue3", fill = "steelblue")+
  geom_smooth(method='lm', color = 'black')+
  xlab('Word memorability')+
  ylab('Image memorability')+
  ggtitle('Low Representativeness')+
  theme_classic()

p.rep.high = rep.high %>% ggplot(aes(x = word.mem, y = Memorability))+
  geom_point(size = 3, alpha = 0.5, color = "steelblue3", fill = "steelblue")+
  geom_smooth(method='lm', color = 'black')+
  xlab('Word memorability')+
  ylab('Image memorability')+
  ggtitle('High Representativeness')+
  theme_classic()
  
p.rep = grid.arrange(p.rep.low, p.rep.high, ncol = 2)
ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/rep.png', plot = p.rep, width = 8, height = 4, units = 'in')

cor.test(rep.high$word.mem, rep.high$Memorability)

# mean rep for image mem in low vs. high 
rep.mem = melt(mem, id.vars = c("word", "rep.split"), measure.vars = c("Memorability", "word.mem"))
rep.mem %>% ggplot(aes(x = variable, y = value, fill = rep.split)) +
  geom_bar(position = "dodge", stat="summary")
```   


## Experiment 2B

### Distribution of word memorability

Plot the distribution of image memorability scores. The vertical line represents for the median of memorability scores = 0.19

The lowest one is **skittles**, and the highest one is **omelet**

```{r}
## ggplot histogram
ggplot(mem['word.mem'], aes(x=word.mem)) + 
  geom_histogram(color="steelblue", fill="white", bins = 25) + 
  geom_vline(xintercept = 0.19,linetype = "dashed") +
  theme_classic()

ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/hist_word_m.png', width = 7, height = 4, units = 'in')
```

### consistency analysis


## Experiment 2C

```{r}
## load word choice data
rating.w = read.csv('C:/Users/Christine/Box Sync/data/mem_dm_all_results/cleaned data/word/cleaned_rating.csv')
choice.w = read.csv('C:/Users/Christine/Box Sync/data/mem_dm_all_results/cleaned data/word/cleaned_choice.csv') %>% mutate(abs.delta.v.z = abs(z.delta.value))

#calculate z delta mem
choice.w = choice.w %>% mutate(abs.delta.v.z = abs(z.delta.value),
                               chosehigh.value = case_when(choseright == 1 & delta.value >=0 ~ 1, choseright == 0 & delta.value <0 ~ 1, choseright == 1 & delta.value <0 ~ 0,choseright == 0 & delta.value >=0 ~ 0 ))

```

### choice ~ word value  
```{r}
#generate the model
m.w.v = glmer(chosehigh.value~1+abs.delta.v.z+(1+abs.delta.v.z|ID), 
           data = choice.w, family = "binomial")
```

```{r}
p1.w <- ggpredict(m.w.v, terms = "abs.delta.v.z [all]") 

p.w <- ggplot(p1, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p1$conf.low, ymax = p1$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() + ylim(0.4, 1.0) + xlim(0,3) 

#calculate mean/sd for each actual data point
choice.v.plt <- choice.w %>% 
  filter(delta.value != 0) %>%
  #dplyr::group_by(ID) %>%
  mutate(bin.value=ntile(abs.delta.v.z, 5))
#for abs.delta.value
choice.plt.ppl = choice.v.plt %>% group_by(bin.value, ID) %>%
  summarise_at(vars(abs.delta.v.z, chosehigh.value), list(mean = mean))
choice.plt.df = choice.plt.ppl %>% group_by(bin.value) %>%
  summarise_at(vars(abs.delta.v.z_mean, chosehigh.value_mean), list(mean = mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.df$lowSE <- choice.plt.df$chosehigh.value_mean_mean - (choice.plt.df$chosehigh.value_mean_sd)/sqrt(44)
choice.plt.df$highSE <- choice.plt.df$chosehigh.value_mean_mean + (choice.plt.df$chosehigh.value_mean_sd)/sqrt(44)

p.w = p.w + geom_pointrange(data = choice.plt.df, aes(x = abs.delta.v.z_mean_mean, y = chosehigh.value_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE)+ xlab("Absolute Delta Value") + ylab("Probability of Choosing Higher Valued Item")

p.w


```

```{r}
choice.w.plt <- choice.w %>% 
  filter(delta.value != 0) %>%
  dplyr::group_by(ID) %>%
  mutate(bin.value=ntile(abs.delta.v.z, 5))

m3.word = lmer(rt ~ abs.delta.v.z + (abs.delta.v.z|ID), 
           data = choice.v.plt)

p3 <- ggpredict(m3.word, terms = "abs.delta.v.z") 

p.rt.w.v <- ggplot(p3, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p3$conf.low, ymax = p3$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() + xlim(0,3) 

#calculate mean/sd for each actual data point

#for abs.delta.value
choice.plt.ppl = choice.v.plt %>% group_by(bin.value, ID) %>%
  summarise_at(vars(abs.delta.v.z, chosehigh.value, rt), list(mean = mean))
choice.plt.df = choice.plt.ppl %>% group_by(bin.value) %>%
  summarise_at(vars(abs.delta.v.z_mean, chosehigh.value_mean, rt_mean), list(mean=mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.df$lowSE <- choice.plt.df$rt_mean_mean - (choice.plt.df$rt_mean_sd)/sqrt(44)
choice.plt.df$highSE <- choice.plt.df$rt_mean_mean + (choice.plt.df$rt_mean_sd)/sqrt(44)

p.rt.w.v = p.rt.w.v + geom_pointrange(data = choice.plt.df, aes(x = abs.delta.v.z_mean_mean, y = rt_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Absolute Delta Value") + ylab("RT")

p.rt.w.v
```


### choice ~ word mem

```{r}
## filter data into trials that delta value close to 0
#split trials into high/low delta mem based on within-subject median
choice.w = choice.w %>% 
  arrange(ID, abs.delta.v.z) %>% 
  group_by(ID) %>% 
  dplyr::mutate(rank = 1:n()) %>% 
  ungroup()
choice.w.low = choice.w %>% dplyr::group_by(ID) %>% slice(seq(0.5 * n())) %>% 
  mutate(bin.absmem = 1)

# generate the model
m.w.m = glmer(choseright~1+delta.mem+(1+delta.mem|ID),
           data = choice.w.low, family = "binomial",
           glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
summary(m.w.m)

```

```{r}
p2.w <- ggpredict(m.w.m, terms = "delta.mem [all]") 

p.mem.w.choice <- ggplot(p2.w, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p2.w$conf.low, ymax = p2.w$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic() 
#+ ylim(0.4, 1.2) + xlim(-0.1,3) 

p.mem.w.choice = p.mem.w.choice + scale_y_continuous(labels = scales::percent, limits = c(0,1)) +
  xlab("Delta Memorability") +
  scale_y_continuous(labels = scales::percent, limits = c(0,1))+
  scale_x_continuous(limits = c(-0.8,0.8))

#calculate mean/sd for each actual data point
choice.m.plt <- choice.w.low %>% 
  dplyr::group_by(ID) %>%
  mutate(bin.mem=ntile(delta.mem, 5))
#for abs.delta.value
choice.plt.mem.ppl = choice.m.plt %>% group_by(bin.mem, ID) %>%
  summarise_at(vars(delta.mem, choseright, rt), list(mean = mean))
choice.plt.mem.df = choice.plt.mem.ppl %>% group_by(bin.mem) %>%
  summarize_at(vars(delta.mem_mean, choseright_mean, rt_mean), list(mean=mean, sd = sd))

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$choseright_mean_mean - (choice.plt.mem.df$choseright_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$choseright_mean_mean + (choice.plt.mem.df$choseright_mean_sd)/sqrt(44)

p.mem.w.choice = p.mem.w.choice + geom_pointrange(data = choice.plt.mem.df, aes(x = delta.mem_mean_mean, y = choseright_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("Probability of Choosing Right")

p.mem.w.choice
```

```{r}

m4.value.w = lmer(rt ~ delta.mem + (delta.mem|ID), 
           data = choice.m.plt)

p4.w <- ggpredict(m4.value.w, terms = "delta.mem") 

p.mem.w.rt <- ggplot(p4.w, aes(x = x, y = predicted)) + geom_line(show.legend = FALSE) + 
  geom_ribbon(aes(ymin = p4.w$conf.low, ymax = p4.w$conf.high),alpha = 0.3, linetype =1, show.legend = FALSE) + theme_classic()+ xlim(-0.8,0.8) 


p.mem.w.rt

# calculate the lower and upper limits based on 1 standard error from the mean - divide sd by sqrt of 70 (approx number of subjs in each quintile)
choice.plt.mem.df$lowSE <- choice.plt.mem.df$rt_mean_mean - (choice.plt.mem.df$rt_mean_sd)/sqrt(44)
choice.plt.mem.df$highSE <- choice.plt.mem.df$rt_mean_mean + (choice.plt.mem.df$rt_mean_sd)/sqrt(44)

p.mem.w.rt = p.mem.w.rt + geom_pointrange(data = choice.plt.mem.df, aes(x = delta.mem_mean_mean, y = rt_mean_mean, ymin = lowSE, ymax = highSE), show.legend = FALSE) + 
  xlab("Delta Memorability") + ylab("RT")

p.mem.w.rt
```


```{r}
p.word.v = grid.arrange(p.w, p.rt.w.v, nrow=2)
p.word.m = grid.arrange(p.mem.w.choice, p.mem.w.rt, nrow=2)
p.word = grid.arrange(p.word.v, p.word.m, ncol = 2)
ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/word_choice_m.png', plot = p.word, width = 7, height = 6, units = 'in')
```


## Supplement  
### Variances of delta memorability and delta value 
```{r, warning = FALSE}
#plot abs delta mem
choice %>% ggplot(aes(x = abs.mem, fill=..count..))+
  geom_histogram(binwidth = 0.05)+
  theme_classic()+
  xlim(0,1)+
  ggtitle('Distirbution of Delta Memorbaility')+
  xlab('Delta Memorability')
ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/delta_mem_image.png', width = 8, height = 6, units = 'in')

## plot the abs delta mem for words
choice.w %>% ggplot(aes(x = abs.mem, fill=..count..))+
  geom_histogram(binwidth = 0.05)+
  theme_classic()+
  xlim(0,1)+
  ggtitle('Distirbution of Delta Memorbaility')+
  xlab('Delta Memorability')
ggsave('C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/delta_mem_word.png', width = 8, height = 6, units = 'in')
``` 

### Correlation Matrix

Plot for correlation matrix between 17 ratings and memorability.

```{r corrMatrix, out.width = "600px", message = FALSE}
rdat = food %>% dplyr::select(stimulus, choice.rating, starts_with("rating"))
colnames(rdat) = sub("rating[.]", "", colnames(rdat))
colnames(rdat) = sub("[.]rating", "", colnames(rdat))

rmat = as.matrix(rdat[,-1])
rownames(rmat) = rdat$stimulus
rmat.nochoice = rmat[,-1]

new.ord = c("tasty", "othertasty", "feel", "texture", "disgusting", "familiar", "filling", "healthy", "sweetsaltysavory", "calories", "carbohydrates", "fat", "vitamins", "gluten", "sodium", "sugar", "protein", "stimulus")


# correlation matrix with memorability score
ave.mat.r = rdat[,new.ord] %>% 
  group_by(stimulus) %>% 
  summarise_all(mean) 
# matching memorability stimulus name to food data stimulus name
ave.mat.r = data.frame(memorability = mem$Memorability, mem.stimulus = mem$X, rep = mem$rep.z, DNN = mem$ResMem, HR = mem$HR.x, ave.mat.r)

M.mem = ave.mat.r %>% dplyr::select(-mem.stimulus, -stimulus) %>% cor()
diag(M.mem) = 0
png(height=800, width=800, file="C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/corr_m.png", type = "cairo")
corrplot(M.mem, method="circle", diag = F, #order="hclust", 
         #is.corr=F, cl.lim=c(-0.85,0.85), 
         col=rev(colorRampPalette(brewer.pal(n=11, name="RdBu"))(256)),
         tl.col='black',
         #tl.cex=1.2,
         addCoef.col="grey35",
         type = "upper")

dev.off()

knitr::include_graphics("C:/Users/Christine/Box Sync/data/mem_dm_all_results/visualization/corr_m.png")
```

### Table of corresponding images and words